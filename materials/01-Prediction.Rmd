---
title: "01-Prediction"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(AmesHousing)
library(tidymodels)
library(tune)

ames <- make_ames() %>% 
  dplyr::select(-matches("Qu"))

fit_data <- function(formula, model, data, ...) {
  wf <- workflows::add_model(workflows::add_formula(workflows::workflow(), formula), model)
  fit(wf, data, ...)
}

fit_split <- function(formula, model, split, ...) {
  wf <- workflows::add_model(workflows::add_formula(workflows::workflow(), formula, blueprint = hardhat::default_formula_blueprint(indicators = FALSE, allow_novel_levels = TRUE)), model)
  tune::last_fit(wf, split, ...)
}
```

# Day One - How to get good predictions from models  

***

## 1. What is Machine Learning?

### Your Turn 1

Work together in your team to fill out as much of the handout as you can. Feel free to leave some blank.

### Your Turn 2

Let's review the handout answers in light of our conversation.

### Recap: Machine Learning is not Hypothesis Testing

Hypotheses drive how we typically use models, but Machine Learning doesn’t use hypotheses. Machine Learning is about making great predictions—period. As a result, Machine Learners must choose the things a hypothesis usually dictates:

* **Which data to use?** We call this feature engineering.  
* **Which criteria to use?** We call this model assessment.  
* **Which model to use?** We call this model selection and tuning.  

This creates a large practical difference between Machine Learning and Hypothesis testing. At the end of the day, Machine Learners will evaluate _many_ different types of models for a single problem.

***

## What is a model? (i.e. "Prediction")

<!--slides: 01-ames/13-->
<!--slides: 01-lm/18-->
<!--slides: 03-parsnip/33-->

### Your Turn 1

Write a pipe that creates a learner that uses `lm()` to fit a linear regression. Save it as `lm_spec` and look at the object. What does it return?

```{r}
lm_spec <- 
   linear_reg() %>% # Pick linear regression
   set_engine(engine = "lm") # set engine
lm_spec
```

<!--slides: fitting a model-new?-->

# Your Turn 2

Double check. Does

```{r}
lm_fit <- fit_data(Sale_Price ~ Gr_Liv_Area, model = lm_spec, data = ames)
lm_fit
```

give the same results as

```{r}
lm(Sale_Price ~ Gr_Liv_Area, data = ames)
```

<!--slides: ???-->

# Your Turn 3

Challenge: can you fit the model that uses `Bedroom_AbvGr`, `Full_Bath` and `Half_Bath` to predict `Sale_Price`? Save the result as `bedbath_fit`.

```{r}
bedbath_fit <- fit_data(Sale_Price ~ Bedroom_AbvGr + Full_Bath + Half_Bath, model = lm_spec, data = ames)
bedbath_fit
```

<!--slides: 02-overfitting/21-->

# Your Turn 4

(Slide of overfit and appropriately fit models)
In your teams, decide which model:

1. Has the smallest residuals  
2. Will have lower prediction error. Why?  

<!--slides: 02-data splitting/28-->

# Your Turn 5

Fill in the blanks. Use `initial_split()`, `training()`, `testing()`, `fit_data()` and `predict()` to

1. Split ames into training and test sets. Save the rsplit!  
2. Extract the training data. Fit a linear model to it. Save the model!  
3. Extract the test data.  
4. Use your linear model to predict the values in your test set.  
5. Keep `set.seed(100)` at the start of your code.  

*Hint: Be sure to remove every `_` before running the code!*

```{r}
set.seed(100) # Important!
ames_split <- initial_split(ames)

ames_train <- training(ames_split)
lm_fit <- fit_data(Sale_Price ~ Gr_Liv_Area, 
                   model = lm_spec, 
                   data = ames_train)

ames_test <- testing(ames_split)
lm_pred <- predict(lm_fit, new_data = ames_test)
```

<!--slides: 02-performance/06-->

# Your Turn 6

Compute the test RMSE for our `Sale_Price ~ Bedroom_AbvGr + Full_Bath + Half_Bath` model. You will need to train the model on `ames_train` and use the result to predict the values of `ames_test`.

```{r}
bb_fit <- fit_data(Sale_Price ~ Bedroom_AbvGr + Full_Bath + Half_Bath, model = lm_spec, data = ames_train)

bb_pred <- predict(bb_fit, new_data = ames_test)

rmse_vec(truth = ames_test$Sale_Price, estimate = bb_pred$.pred)
```

<!--slides: new?-->

# Your Turn 7

Wrap this all up with `fit_split()` and `collect_metrics()`.

```{r}
fit_split(Sale_Price ~ Bedroom_AbvGr + Full_Bath + Half_Bath, model = lm_spec, split = ames_split) %>% collect_metrics()
```

<!--slides: new?-->

# Your Turn 8

Brief detour from models- 20 questions guessing game. Challenge: write down your rules as you go. 

# Your Turn 9

<!--I'll provide a tree with max depth of 3 here-->

Take this tree and answer the following:

1. How many decision nodes are there?

2. How many leaf nodes are there?

Then derive a set of decision rules for predicting of the form:

> if condition1 and condition2 and condition3 then outcome.

Hint: you'll need 1 rule per leaf node.

# Your Turn 10

Write a pipe to create a model that uses the rpart package to fit a regression tree. Save it as `rt_spec` and look at the object. What does it return?

```{r}
rt_spec <- 
  decision_tree() %>%          
  set_engine(engine = "rpart") %>% 
  set_mode("regression")
rt_spec
```

# Your Turn 11

Use `fit_split()` and `collect_metrics()` again, this time to fit a regression tree model to the training data with formula = Sale_Price ~ Gr_Liv_Area; then predict new sale prices with the testing data. Compare the rmse here to one using the linear model for the same formula- which is better?

```{r}
fit_split(Sale_Price ~ Gr_Liv_Area, 
          model = lm_spec, 
          split = ames_split) %>% 
  collect_metrics()

set.seed(100) # Important!
fit_split(Sale_Price ~ Gr_Liv_Area, 
          model = rt_spec, 
          split = ames_split) %>% 
  collect_metrics()
```


### Recap: A model need not be a line, or even interpretable

For Machine Learning, a model only needs to return predictions. This broadens our idea of models to include things like those listed below. You’ll need a common syntax to move easily between them.

* **Linear models** - Linear models represent the information contained within data with an equation that is easy to interpret, at least hypothetically.  

* **Decision Trees** - Decision trees represent the information contained within data with a series of rules or decisions.  

* **K Nearest Neighbors** - K Nearest Neighbors represent the information contained within data with the data itself. They are almost an anti-model.  

Let's practice that syntax with a simple problem: predicting house prices with a linear model.
